{"cells": [{"cell_type": "code", "execution_count": 108, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "pd.set_option('display.max_columns', None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For this exercise we will work through the different steps of a linear regression workflow.  We will:\n", "\n", "### FSM\n", "1. Load in the dataset: inspect the overall shape, duplicate entries, and na's.\n", "2. Identify the continuous target variable\n", "3. Perform Initial EDA: correlation plots\n", "4. Build a FSM (First Simple Model) with statsmodels/Build a FSM with sklearn\n", "5. Check the assumptions of linear regression  \n", "\n", "### Iterate: Build a better model\n", "6. Identify independent variables, and differentiate between numerical vs categorical features\n", "7. Identify and remove outliers  \n", "8. Check for duplicate entries and nas\n", "9. Scale continuous features  \n", "10. Add more continuous features refit, compare R2, check assumptions  \n", "\n", "### Iterate: Build a better model\n", "10. Encode categorical variables\n", "11. Add a categorical variable to the model, refit compare R2, check assumptions\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Dataset\n", "We will use a dataset from [Kaggle](https://www.kaggle.com/kumarajarshi/life-expectancy-who). It contains data collected by the WHO about life expectancy and potentially-related factors.  The information is aggregated on a per-country per-year basis.\n", "\n", "The following questions have been posed. Read them and keep them in your mind when building your model.  We will reference them as we proceed through the workflow.\n", "\n", "1. Do various predicting factors which have been chosen initially really affect life expectancy? Which predicting variables actually affect life expectancy?\n", "2. Should a country having a lower life expectancy value(<65) increase its healthcare expenditure in order to improve its average lifespan?\n", "3. How do infant and adult mortality rates affect life expectancy?\n", "4. Does life expectancy have positive or negative correlation with eating habits, lifestyle, exercise, smoking, drinking alcohol etc.\n", "5. What is the impact of schooling on the lifespan of humans?\n", "6. Does Life expectancy have positive or negative relationship with drinking alcohol?\n", "7. Do densely populated countries tend to have lower life expectancy?\n", "8. What is the impact of immunization coverage on life Expectancy?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Load in the dataset and check the overall shape\n"]}, {"cell_type": "code", "execution_count": 109, "metadata": {}, "outputs": [], "source": ["# load in the dataset\n", "df = None\n", "\n", "# How many records are in the data set?\n", "records = None\n", "\n", "# How many columns are in the dataset?\n", "columns = None\n", "\n", "# Check for duplicate entries\n", "\n", "# Check for na's (just look to get an idea; don't drop or impute yet)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 3. What does a row in the dataframe represent?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2: Identify the continous target variable"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you had problems isolating that variable, don't worry.  That is on purpose! \n", "There can be odd, burdensome inconsistencies in naming of data.\n", "Let's use our Python skills to wipe out the naming inconsistencies."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Clean up the column names. \n", "There are many ways to do this. One way of doing so, outlined below, uses the columns attribute of the dataframe.  Then, using a list comprehension or for loop, we can manipulate the column name strings using methods that come with the string class."]}, {"cell_type": "code", "execution_count": 112, "metadata": {}, "outputs": [], "source": ["# 1. Gather column names into a variable\n", "columns = None\n", "\n", "# 2. Strip whitespace from the ends\n", "columns = None\n", "\n", "# 3. Replace white space with underscores\n", "columns = None\n", "\n", "# 4. Make all columns characters lowercase\n", "columns = None\n", "\n", "# 5. Reset the column names of the dataframe\n", "# df.columns = columns"]}, {"cell_type": "code", "execution_count": 145, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>life_expectancy</th>\n", "      <th>country</th>\n", "      <th>year</th>\n", "      <th>status</th>\n", "      <th>adult_mortality</th>\n", "      <th>infant_deaths</th>\n", "      <th>alcohol</th>\n", "      <th>percentage_expenditure</th>\n", "      <th>hepatitis_b</th>\n", "      <th>measles</th>\n", "      <th>bmi</th>\n", "      <th>under-five_deaths</th>\n", "      <th>polio</th>\n", "      <th>total_expenditure</th>\n", "      <th>diphtheria</th>\n", "      <th>hiv/aids</th>\n", "      <th>gdp</th>\n", "      <th>population</th>\n", "      <th>thinness__1-19_years</th>\n", "      <th>thinness_5-9_years</th>\n", "      <th>income_composition_of_resources</th>\n", "      <th>schooling</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>65.0</td>\n", "      <td>Afghanistan</td>\n", "      <td>2015</td>\n", "      <td>Developing</td>\n", "      <td>263.0</td>\n", "      <td>62</td>\n", "      <td>0.01</td>\n", "      <td>71.279624</td>\n", "      <td>65.0</td>\n", "      <td>1154</td>\n", "      <td>19.1</td>\n", "      <td>83</td>\n", "      <td>6.0</td>\n", "      <td>8.16</td>\n", "      <td>65.0</td>\n", "      <td>0.1</td>\n", "      <td>584.259210</td>\n", "      <td>33736494.0</td>\n", "      <td>17.2</td>\n", "      <td>17.3</td>\n", "      <td>0.479</td>\n", "      <td>10.1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>59.9</td>\n", "      <td>Afghanistan</td>\n", "      <td>2014</td>\n", "      <td>Developing</td>\n", "      <td>271.0</td>\n", "      <td>64</td>\n", "      <td>0.01</td>\n", "      <td>73.523582</td>\n", "      <td>62.0</td>\n", "      <td>492</td>\n", "      <td>18.6</td>\n", "      <td>86</td>\n", "      <td>58.0</td>\n", "      <td>8.18</td>\n", "      <td>62.0</td>\n", "      <td>0.1</td>\n", "      <td>612.696514</td>\n", "      <td>327582.0</td>\n", "      <td>17.5</td>\n", "      <td>17.5</td>\n", "      <td>0.476</td>\n", "      <td>10.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>59.9</td>\n", "      <td>Afghanistan</td>\n", "      <td>2013</td>\n", "      <td>Developing</td>\n", "      <td>268.0</td>\n", "      <td>66</td>\n", "      <td>0.01</td>\n", "      <td>73.219243</td>\n", "      <td>64.0</td>\n", "      <td>430</td>\n", "      <td>18.1</td>\n", "      <td>89</td>\n", "      <td>62.0</td>\n", "      <td>8.13</td>\n", "      <td>64.0</td>\n", "      <td>0.1</td>\n", "      <td>631.744976</td>\n", "      <td>31731688.0</td>\n", "      <td>17.7</td>\n", "      <td>17.7</td>\n", "      <td>0.470</td>\n", "      <td>9.9</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>59.5</td>\n", "      <td>Afghanistan</td>\n", "      <td>2012</td>\n", "      <td>Developing</td>\n", "      <td>272.0</td>\n", "      <td>69</td>\n", "      <td>0.01</td>\n", "      <td>78.184215</td>\n", "      <td>67.0</td>\n", "      <td>2787</td>\n", "      <td>17.6</td>\n", "      <td>93</td>\n", "      <td>67.0</td>\n", "      <td>8.52</td>\n", "      <td>67.0</td>\n", "      <td>0.1</td>\n", "      <td>669.959000</td>\n", "      <td>3696958.0</td>\n", "      <td>17.9</td>\n", "      <td>18.0</td>\n", "      <td>0.463</td>\n", "      <td>9.8</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>59.2</td>\n", "      <td>Afghanistan</td>\n", "      <td>2011</td>\n", "      <td>Developing</td>\n", "      <td>275.0</td>\n", "      <td>71</td>\n", "      <td>0.01</td>\n", "      <td>7.097109</td>\n", "      <td>68.0</td>\n", "      <td>3013</td>\n", "      <td>17.2</td>\n", "      <td>97</td>\n", "      <td>68.0</td>\n", "      <td>7.87</td>\n", "      <td>68.0</td>\n", "      <td>0.1</td>\n", "      <td>63.537231</td>\n", "      <td>2978599.0</td>\n", "      <td>18.2</td>\n", "      <td>18.2</td>\n", "      <td>0.454</td>\n", "      <td>9.5</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   life_expectancy      country  year      status  adult_mortality  \\\n", "0             65.0  Afghanistan  2015  Developing            263.0   \n", "1             59.9  Afghanistan  2014  Developing            271.0   \n", "2             59.9  Afghanistan  2013  Developing            268.0   \n", "3             59.5  Afghanistan  2012  Developing            272.0   \n", "4             59.2  Afghanistan  2011  Developing            275.0   \n", "\n", "   infant_deaths  alcohol  percentage_expenditure  hepatitis_b  measles   bmi  \\\n", "0             62     0.01               71.279624         65.0     1154  19.1   \n", "1             64     0.01               73.523582         62.0      492  18.6   \n", "2             66     0.01               73.219243         64.0      430  18.1   \n", "3             69     0.01               78.184215         67.0     2787  17.6   \n", "4             71     0.01                7.097109         68.0     3013  17.2   \n", "\n", "   under-five_deaths  polio  total_expenditure  diphtheria  hiv/aids  \\\n", "0                 83    6.0               8.16        65.0       0.1   \n", "1                 86   58.0               8.18        62.0       0.1   \n", "2                 89   62.0               8.13        64.0       0.1   \n", "3                 93   67.0               8.52        67.0       0.1   \n", "4                 97   68.0               7.87        68.0       0.1   \n", "\n", "          gdp  population  thinness__1-19_years  thinness_5-9_years  \\\n", "0  584.259210  33736494.0                  17.2                17.3   \n", "1  612.696514    327582.0                  17.5                17.5   \n", "2  631.744976  31731688.0                  17.7                17.7   \n", "3  669.959000   3696958.0                  17.9                18.0   \n", "4   63.537231   2978599.0                  18.2                18.2   \n", "\n", "   income_composition_of_resources  schooling  \n", "0                            0.479       10.1  \n", "1                            0.476       10.0  \n", "2                            0.470        9.9  \n", "3                            0.463        9.8  \n", "4                            0.454        9.5  "]}, "execution_count": 145, "metadata": {}, "output_type": "execute_result"}], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": 114, "metadata": {}, "outputs": [], "source": ["# Lastly, to make things easier to interpet, set the target to column index 0\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 117, "metadata": {}, "outputs": [], "source": ["# Revisit the continuous target variable.  \n", "# Explore it a bit.  Plot a histogram of its distribution as well a boxplot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 3. Perform Initial EDA\n", "\n", "There are a lot of variables here!  Let's look at a correlation matrix to see which ones might be the most useful.  (Here we are looking for variables that are highly correlated with the target variable, but not highly correlated with other input variables)"]}, {"cell_type": "code", "execution_count": 120, "metadata": {}, "outputs": [], "source": ["# create a correlation matrix\n", "# first, just use the datafram .corr() method to output a numerical matrix\n"]}, {"cell_type": "code", "execution_count": 121, "metadata": {}, "outputs": [], "source": ["# Then pass the above code into Seaborn's heatmap plot\n"]}, {"cell_type": "code", "execution_count": 122, "metadata": {}, "outputs": [], "source": ["# Try adding the code in this cell to the mask attribute in the heatmap to halve the plot\n", "mask = np.triu(np.ones_like(df.corr(), dtype=np.bool))"]}, {"cell_type": "code", "execution_count": 124, "metadata": {}, "outputs": [], "source": ["# Judging from the correlation matrix or the heatmap, which three features have the highest positive correlation? \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use seaborn's pairplot function on the three features above plus life_expectancy.  \n", "Note: we would usually start right off by using a pairplot, but because we have so many features, the pairplot would be unwieldy."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Judging from the top row of the pairplot, one feature's correlation to the target is a bit fuzzier than the rest. \n", "Inspecting other cells of the pairplot, the other two features show covariance. \n", "Given those two insights, choose one feature to build the First Simple Model with.\n", "Consider also whether choosing one of the positively correlated features above the others would help answer any of the question listed at the beginning of the notebook.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 4. Build an FSM"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. FSM with Statsmodels\n"]}, {"cell_type": "code", "execution_count": 133, "metadata": {}, "outputs": [], "source": ["from statsmodels.formula.api import ols\n", "# Create a dataframe with only the target and the chosen high-positive corellation feature\n", "fsm_df = None\n", "# For this FSM, simply dropnas.\n", "\n", "# build the R-style formula. The format is \"target~feature_1 + feature_2 + feature_3\"\n", "formula = None\n", "\n", "# Fit the model on the dataframe composed of the two features\n", "fsm = ols(formula=formula, data=fsm_df).fit()"]}, {"cell_type": "code", "execution_count": 143, "metadata": {}, "outputs": [{"data": {"text/html": ["<table class=\"simpletable\">\n", "<caption>OLS Regression Results</caption>\n", "<tr>\n", "  <th>Dep. Variable:</th>     <td>life_expectancy</td> <th>  R-squared:         </th> <td>   0.565</td> \n", "</tr>\n", "<tr>\n", "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.565</td> \n", "</tr>\n", "<tr>\n", "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3599.</td> \n", "</tr>\n", "<tr>\n", "  <th>Date:</th>             <td>Wed, 10 Jun 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n", "</tr>\n", "<tr>\n", "  <th>Time:</th>                 <td>14:44:43</td>     <th>  Log-Likelihood:    </th> <td> -8964.3</td> \n", "</tr>\n", "<tr>\n", "  <th>No. Observations:</th>      <td>  2768</td>      <th>  AIC:               </th> <td>1.793e+04</td>\n", "</tr>\n", "<tr>\n", "  <th>Df Residuals:</th>          <td>  2766</td>      <th>  BIC:               </th> <td>1.794e+04</td>\n", "</tr>\n", "<tr>\n", "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n", "</tr>\n", "<tr>\n", "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n", "</tr>\n", "</table>\n", "<table class=\"simpletable\">\n", "<tr>\n", "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n", "</tr>\n", "<tr>\n", "  <th>Intercept</th> <td>   44.1089</td> <td>    0.437</td> <td>  100.992</td> <td> 0.000</td> <td>   43.252</td> <td>   44.965</td>\n", "</tr>\n", "<tr>\n", "  <th>schooling</th> <td>    2.1035</td> <td>    0.035</td> <td>   59.995</td> <td> 0.000</td> <td>    2.035</td> <td>    2.172</td>\n", "</tr>\n", "</table>\n", "<table class=\"simpletable\">\n", "<tr>\n", "  <th>Omnibus:</th>       <td>283.391</td> <th>  Durbin-Watson:     </th> <td>   0.267</td> \n", "</tr>\n", "<tr>\n", "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1122.013</td> \n", "</tr>\n", "<tr>\n", "  <th>Skew:</th>          <td>-0.445</td>  <th>  Prob(JB):          </th> <td>2.28e-244</td>\n", "</tr>\n", "<tr>\n", "  <th>Kurtosis:</th>      <td> 5.989</td>  <th>  Cond. No.          </th> <td>    46.7</td> \n", "</tr>\n", "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."], "text/plain": ["<class 'statsmodels.iolib.summary.Summary'>\n", "\"\"\"\n", "                            OLS Regression Results                            \n", "==============================================================================\n", "Dep. Variable:        life_expectancy   R-squared:                       0.565\n", "Model:                            OLS   Adj. R-squared:                  0.565\n", "Method:                 Least Squares   F-statistic:                     3599.\n", "Date:                Wed, 10 Jun 2020   Prob (F-statistic):               0.00\n", "Time:                        14:44:43   Log-Likelihood:                -8964.3\n", "No. Observations:                2768   AIC:                         1.793e+04\n", "Df Residuals:                    2766   BIC:                         1.794e+04\n", "Df Model:                           1                                         \n", "Covariance Type:            nonrobust                                         \n", "==============================================================================\n", "                 coef    std err          t      P>|t|      [0.025      0.975]\n", "------------------------------------------------------------------------------\n", "Intercept     44.1089      0.437    100.992      0.000      43.252      44.965\n", "schooling      2.1035      0.035     59.995      0.000       2.035       2.172\n", "==============================================================================\n", "Omnibus:                      283.391   Durbin-Watson:                   0.267\n", "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1122.013\n", "Skew:                          -0.445   Prob(JB):                    2.28e-244\n", "Kurtosis:                       5.989   Cond. No.                         46.7\n", "==============================================================================\n", "\n", "Warnings:\n", "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n", "\"\"\""]}, "execution_count": 143, "metadata": {}, "output_type": "execute_result"}], "source": ["# Use the summary() method on the fsm varaible to print out the results of the fit.\n", "fsm.summary()"]}, {"cell_type": "code", "execution_count": 163, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Rsquared of FSM: None\n", "----------\n", "Beta values of FSM:\n", "None\n"]}], "source": ["# The object also has attributes associated with the ouput, such as: rsquared, and params.\n", "# save those values to the variables below.\n", "\n", "rsquared = None\n", "params = None\n", "\n", "print(f'Rsquared of FSM: {rsquared}')\n", "print('----------')\n", "print('Beta values of FSM:')\n", "print(params)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interpret the result of the FSM.  What does the R Squared tell you? Remember the formula for:\n", "\n", "$\\Large R^2 = 1 - \\frac{SSE}{SST}$\n", "\n", "Also, interepret the coefficients.  If we increase the value of our independent variable by 1, what does it mean for our predicted value?\n", "\n", "What is will our model predict the value of Life Expectancy to be for a country with 0 years of school on average?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 5 Check the assumptions of Linear Regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1. Linearity"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Linearity\n", "\n", "Linear regression assumes that the input variable linearly predicts the output variable.  We already qualitatively checked that with a scatter plot.  But I also think it's a good idea to use a statistical test.  This one is the [Rainbow test](https://www.tandfonline.com/doi/abs/10.1080/03610928208828423) which is available from the [diagnostic submodule of StatsModels](https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.linear_rainbow.html#statsmodels.stats.diagnostic.linear_rainbow)"]}, {"cell_type": "code", "execution_count": 167, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Rainbow statistic: 1.2910159786411675\n", "Rainbow p-value: 1.057579656507341e-06\n"]}], "source": ["from statsmodels.stats.diagnostic import linear_rainbow, het_breuschpagan\n", "from statsmodels.stats.outliers_influence import variance_inflation_factor\n", "\n", "rainbow_statistic, rainbow_p_value = linear_rainbow(fsm)\n", "print(\"Rainbow statistic:\", rainbow_statistic)\n", "print(\"Rainbow p-value:\", rainbow_p_value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The null hypothesis is that the model is linearly predicted by the features, alternative hypothesis is that it is not.  Thus returning a low p-value means that the current model violates the linearity assumption."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality\n", "\n", "Linear regression assumes that the residuals are normally distributed.  It is possible to check this qualitatively with a Q-Q plot.  The fit model object has an attribute called resid, which is an array of the difference between predicted and real values.  Store the residuals in the variable below, show the qq plot, and interepret. You are looking for the theoretical quantiles and the sample quantiles to line up."]}, {"cell_type": "code", "execution_count": 181, "metadata": {}, "outputs": [{"ename": "AttributeError", "evalue": "'NoneType' object has no attribute 'shape'", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-181-5542eb51c044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqqplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsm_resids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/statsmodels/graphics/gofplots.py\u001b[0m in \u001b[0;36mqqplot\u001b[0;34m(data, dist, distargs, a, loc, scale, fit, line, ax, **plotkwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \"\"\"\n\u001b[1;32m    584\u001b[0m     probplot = ProbPlot(data, dist=dist, distargs=distargs,\n\u001b[0;32m--> 585\u001b[0;31m                          fit=fit, a=a, loc=loc, scale=scale)\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqqplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplotkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/statsmodels/graphics/gofplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dist, fit, distargs, a, loc, scale)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}], "source": ["# Create a qq-plot\n", "\n", "fsm_resids = None\n", "\n", "import statsmodels.api as sm\n", "sm.qqplot(fsm_resids)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Those qqplots don't look so good in the upper right corner."]}, {"cell_type": "markdown", "metadata": {}, "source": ["The [Jarque-Bera](https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test) test is performed automatically as part of the model summary output, labeled **Jarque-Bera (JB)** and **Prob(JB)**.\n", "\n", "The null hypothesis is that the residuals are normally distributed, alternative hypothesis is that they are not.  \n", "What does the JB score output indicate. Does it support the qq-plot?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Homoscadasticity\n", "\n", "Linear regression assumes that the variance of the dependent variable is homogeneous across different value of the independent variable(s).  We can visualize this by looking at the predicted life expectancy vs. the residuals.\n", "\n"]}, {"cell_type": "code", "execution_count": 210, "metadata": {}, "outputs": [], "source": ["# Use the predict() method now available to be called from the fsm variable to store the predictions\n", "y_hat = None\n", "\n", "# plot y_hat against the residuals (stored in fsm_resids) in a scatter plot\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interepret the result. Do you see any patterns that suggest that the residuals exhibit heteroscedasticity?\n"]}, {"cell_type": "markdown", "metadata": {}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's also run a statistical test.  The [Breusch-Pagan test](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test) is available from the [diagnostic submodule of StatsModels](https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.het_breuschpagan.html#statsmodels.stats.diagnostic.het_breuschpagan)"]}, {"cell_type": "code", "execution_count": 220, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Lagrange Multiplier p-value: nan\n", "F-statistic p-value: 2.2825932549972298e-67\n"]}], "source": ["# If you chose schooling, this should run without error\n", "lm, lm_p_value, fvalue, f_p_value = het_breuschpagan(fsm_resids, fsm_df[[\"schooling\"]])\n", "print(\"Lagrange Multiplier p-value:\", lm_p_value)\n", "print(\"F-statistic p-value:\", f_p_value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The null hypothesis is homoscedasticity, alternative hypothesis is heteroscedasticity.  \n", "What does the p-value returned above indicate?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Independence\n", "\n", "The independence assumption means that the independent variables must not be too collinear.  Right now we have only one independent variable, so we don't need to check this yet."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}